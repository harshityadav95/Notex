{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- REST stands for REpresentational State Transfer\n",
    "- API stands for Application Programming Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomy of URL\n",
    "- ```<scheme>://<host>:<port>/<path>```\n",
    "\n",
    "![image.png](https://fopp.umsi.education/books/published/fopp/_images/internet_requests.png)\n",
    "\n",
    "![image.png](https://fopp.umsi.education/books/published/fopp/_images/parameterformat.png)\n",
    "\n",
    "![image.png](https://fopp.umsi.education/books/published/fopp/_images/urlstructure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Request Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You don’t need to use a browser to fetch the contents of a page, though. In Python, there’s a module available, called requests. You can use the get function in the requests module to fetch the contents of a page\n",
    "\n",
    "To summarize, a Response object, in the full implementation of the requests module has the following useful attributes that can be accessed in your program:\n",
    "\n",
    "- .text\n",
    "\n",
    "- .url\n",
    "\n",
    "- .json()\n",
    "\n",
    "- .status_code (not available in Runestone implementation)\n",
    "\n",
    "- .headers (not available in Runestone implementation)\n",
    "\n",
    "- .history (not available in Runestone implementation)\n",
    "\n",
    "! self = lookup HTTP error code list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "page = requests.get(\"https://api.datamuse.com/words?rel_rhy=funny\")\n",
    "print(type(page))\n",
    "print(page.text[:150]) # print the first 150 characters\n",
    "print(page.url) # print the url that was fetched\n",
    "print(\"------\")\n",
    "x = page.json() # turn page.text into a python object\n",
    "print(type(x))\n",
    "print(\"---first item in the list---\")\n",
    "print(x[0])\n",
    "print(\"---the whole list, pretty printed---\")\n",
    "print(json.dumps(x, indent=2)) # pretty print the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using requests.get to encode URL parameters\n",
    "\n",
    "- Fortunately, when you want to pass information as a URL parameter value, you don’t have to remember all the substitutions that are required to encode special characters. Instead, that capability is built into the requests module.\n",
    "\n",
    "-  The get function in the requests module takes an optional parameter called params. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing a google search using the request\n",
    "d = {'q': '\"violins and guitars\"', 'tbm': 'isch'}\n",
    "results = requests.get(\"https://google.com/search\", params=d)\n",
    "print(results.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://fopp.umsi.education/books/published/fopp/_images/urlexamples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"word\":\"money\",\"score\":4415,\"numSyllables\":2},{\"word\":\"honey\",\"score\":1207,\"numSyllables\":2},{\"word\":\"sunny\",\"score\":717,\"numSyllables\":2},{\"word\":\"\n",
      "https://api.datamuse.com/words?rel_rhy=funny\n"
     ]
    }
   ],
   "source": [
    "# Example of passing dictionary as arguments \n",
    "import requests\n",
    "\n",
    "# page = requests.get(\"https://api.datamuse.com/words?rel_rhy=funny\")\n",
    "kval_pairs = {'rel_rhy': 'funny'}\n",
    "page = requests.get(\"https://api.datamuse.com/words\", params=kval_pairs)\n",
    "print(page.text[:150]) # print the first 150 characters\n",
    "print(page.url) # print the url that was fetched\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a function to make repeated invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['money', 'honey', 'sunny']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_rhymes(word):\n",
    "    baseurl = \"https://api.datamuse.com/words\"\n",
    "    params_diction = {} # Set up an empty dictionary for query parameters\n",
    "    params_diction[\"rel_rhy\"] = word\n",
    "    params_diction[\"max\"] = \"3\" # get at most 3 results\n",
    "    resp = requests.get(baseurl, params=params_diction)\n",
    "    # return the top three words\n",
    "    word_ds = resp.json()\n",
    "    return [d['word'] for d in word_ds]\n",
    "    return resp.json() # Return a python object (a list of dictionaries in this case)\n",
    "\n",
    "print(get_rhymes(\"funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching Response Content\n",
    "\n",
    "To avoid re-requesting the same data, we will use a programming pattern known as caching. It works like this:\n",
    "\n",
    "- Before doing some expensive operation (like calling requests.get to get data from a REST API), check whether you have already saved (“cached”) the results that would be generated by making that request.\n",
    "\n",
    "- If so, return that same data.\n",
    "\n",
    "- If not, perform the expensive operation and save (“cache”) the results (e.g. the complicated data) in your cache so you won’t have to perform it again the next time.\n",
    "\n",
    "## The requests_with_caching module\n",
    "In this book, we are providing a special module, called request_with_caching.\n",
    "\n",
    "Here’s how you’ll use this module.\n",
    "\n",
    "- Your code will include a statement to import the module, import requests_with_caching.\n",
    "\n",
    "- Instead of invoking requests.get(), you’ll invoke requests_with_caching.get().\n",
    "\n",
    "There are a couple of other optional parameters for the function requests_with_caching.get().\n",
    "\n",
    "- cache_file– it’s value should be a string specifying the name of the file containing the permanent cache. If you don’t specify anything, the default value is “permanent_cache.txt”. For the datamuse API, we’ve provide a cache in a file called datamuse_cache.txt. It just contains the saved response to the query for “https://api.datamuse.com/words?rel_rhy=funny”.\n",
    "\n",
    "- private_keys_to_ignore– its value should be a list of strings. These are keys from the parameters dictionary that should be ignored when deciding whether the current request matches a previous request. The main purpose of this is that it allows us to return a result from the cache for some REST APIs that would otherwise require you to provide an API key in order to make a request. By default, it is set to [“api_key”], which is a query parameter used with the flickr API. You should not need to set this optional parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "PERMANENT_CACHE_FNAME = \"permanent_cache.txt\"\n",
    "TEMP_CACHE_FNAME = \"this_page_cache.txt\"\n",
    "\n",
    "def _write_to_file(cache, fname):\n",
    "    with open(fname, 'w') as outfile:\n",
    "        outfile.write(json.dumps(cache, indent=2))\n",
    "\n",
    "def _read_from_file(fname):\n",
    "    try:\n",
    "        with open(fname, 'r') as infile:\n",
    "            res = infile.read()\n",
    "            return json.loads(res)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def add_to_cache(cache_file, cache_key, cache_value):\n",
    "    temp_cache = _read_from_file(cache_file)\n",
    "    temp_cache[cache_key] = cache_value\n",
    "    _write_to_file(temp_cache, cache_file)\n",
    "\n",
    "def clear_cache(cache_file=TEMP_CACHE_FNAME):\n",
    "    _write_to_file({}, cache_file)\n",
    "\n",
    "def make_cache_key(baseurl, params_d, private_keys=[\"api_key\"]):\n",
    "    \"\"\"Makes a long string representing the query.\n",
    "    Alphabetize the keys from the params dictionary so we get the same order each time.\n",
    "    Omit keys with private info.\"\"\"\n",
    "    alphabetized_keys = sorted(params_d.keys())\n",
    "    res = []\n",
    "    for k in alphabetized_keys:\n",
    "        if k not in private_keys:\n",
    "            res.append(\"{}-{}\".format(k, params_d[k]))\n",
    "    return baseurl + \"_\".join(res)\n",
    "\n",
    "def get(baseurl, params={}, private_keys_to_ignore=[\"api_key\"], permanent_cache_file=PERMANENT_CACHE_FNAME, temp_cache_file=TEMP_CACHE_FNAME):\n",
    "    full_url = requests.requestURL(baseurl, params)\n",
    "    cache_key = make_cache_key(baseurl, params, private_keys_to_ignore)\n",
    "    # Load the permanent and page-specific caches from files\n",
    "    permanent_cache = _read_from_file(permanent_cache_file)\n",
    "    temp_cache = _read_from_file(temp_cache_file)\n",
    "    if cache_key in temp_cache:\n",
    "        print(\"found in temp_cache\")\n",
    "        # make a Response object containing text from the change, and the full_url that would have been fetched\n",
    "        return requests.Response(temp_cache[cache_key], full_url)\n",
    "    elif cache_key in permanent_cache:\n",
    "        print(\"found in permanent_cache\")\n",
    "        # make a Response object containing text from the change, and the full_url that would have been fetched\n",
    "        return requests.Response(permanent_cache[cache_key], full_url)\n",
    "    else:\n",
    "        print(\"new; adding to cache\")\n",
    "        # actually request it\n",
    "        resp = requests.get(baseurl, params)\n",
    "        # save it\n",
    "        add_to_cache(temp_cache_file, cache_key, resp.text)\n",
    "        return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for Media on iTunes\n",
    "\n",
    "- You’ve already seen an example using the iTunes API in Generating Request URLs. The iTunes API allows users to search for movies, podcasts, music, music videos, tv shows, and books that are hosted on the iTunes site. You can explore the official iTunes API documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests_with_caching'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e1f9d33783bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrequests_with_caching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"term\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Ann Arbor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"entity\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"podcast\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miTunes_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests_with_caching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://itunes.apple.com/search\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermanent_cache_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"itunes_cache.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests_with_caching'"
     ]
    }
   ],
   "source": [
    "import requests_with_caching\n",
    "import json\n",
    "\n",
    "parameters = {\"term\": \"Ann Arbor\", \"entity\": \"podcast\"}\n",
    "iTunes_response = requests_with_caching.get(\"https://itunes.apple.com/search\", params = parameters, permanent_cache_file=\"itunes_cache.txt\")\n",
    "\n",
    "py_data = json.loads(iTunes_response.text)\n",
    "for r in py_data['results']:\n",
    "    print(r['trackName'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode for non-English characters\n",
    "\n",
    "- Python’s strings are in unicode, which allows for characters to be from a much larger alphabet, including more than 75,000 ideographic characters used in Chinese, Japanese, and Korean alphabets. Everything works fine inside Python, for operations like slicing and appending and concatenating strings and using .find() or the in operator\n",
    "\n",
    "- Fortunately, the requests module will normally handle this for us automatically. When we fetch a webpage that is in json format, the webpage will have a header called ‘content-type’ that will say something like application/json; charset=utf8. If it specifies the utf8 character set in that way, the requests module will automatically decode the contents into unicode: requests.get('that web page').text will yield a string, with each of those sequences of one to four bytes coverted into a single character.\n",
    "\n",
    "- If, for some reason, you get json-formatted text that is utf-encoded but the requests module hasn’t magically decoded it for you, the json.loads() function call can take care of the decoding for you. loads() takes an optional parameter, encoding. Its default value is ‘utf-8’, so you don’t need to specify it unless you think the text you have received was in some other encoding than ‘utf-8’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tastedive.com/api/similar?q=Bridesmaids&k=327878-course3p-I4ZNBN4A&type=movies&limit=5\n",
      "https://tastedive.com/api/similar?q=Sherlock+Holmes&k=327878-course3p-I4ZNBN4A&type=movies&limit=5\n",
      "http://www.omdbapi.com/?t=Baby+Mama&apikey=546c6742&r=json\n",
      "http://www.omdbapi.com/?t=The+Five-Year+Engagement&apikey=546c6742&r=json\n",
      "http://www.omdbapi.com/?t=Date+Night&apikey=546c6742&r=json\n",
      "http://www.omdbapi.com/?t=Bachelorette&apikey=546c6742&r=json\n",
      "http://www.omdbapi.com/?t=Bad+Teacher&apikey=546c6742&r=json\n",
      "http://www.omdbapi.com/?t=Sherlock+Holmes%3A+A+Game+Of+Shadows&apikey=546c6742&r=json\n",
      "http://www.omdbapi.com/?t=Prince+Of+Persia%3A+The+Sands+Of+Time&apikey=546c6742&r=json\n",
      "http://www.omdbapi.com/?t=Angels+%26+Demons&apikey=546c6742&r=json\n",
      "http://www.omdbapi.com/?t=Iron+Man&apikey=546c6742&r=json\n",
      "http://www.omdbapi.com/?t=The+Tourist&apikey=546c6742&r=json\n",
      "['Iron Man', 'Date Night', 'The Five-Year Engagement', 'Baby Mama', 'Sherlock Holmes: A Game Of Shadows', 'Bachelorette', 'Bad Teacher', 'Prince Of Persia: The Sands Of Time', 'Angels & Demons', 'The Tourist']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_movies_from_tastedive(movieName, key=\"327878-course3p-I4ZNBN4A\"):\n",
    "    baseurl=\"https://tastedive.com/api/similar\"\n",
    "    params_d = {}\n",
    "    params_d[\"q\"]= movieName\n",
    "    params_d[\"k\"]= key\n",
    "    params_d[\"type\"]= \"movies\"\n",
    "    params_d[\"limit\"] = \"5\"\n",
    "    resp = requests.get(baseurl, params=params_d)\n",
    "    print(resp.url)\n",
    "    respDic = resp.json()\n",
    "    return respDic \n",
    "\n",
    "def extract_movie_titles(movieName):\n",
    "    result=[]\n",
    "    for listRes in movieName['Similar']['Results']:\n",
    "        result.append(listRes['Name'])\n",
    "    return result\n",
    "\n",
    "def get_related_titles(listMovieName):\n",
    "    if listMovieName != []:\n",
    "        auxList=[]\n",
    "        relatedList=[]\n",
    "        for movieName in listMovieName:\n",
    "            auxList = extract_movie_titles(get_movies_from_tastedive(movieName))\n",
    "            for movieNameAux in auxList:\n",
    "                if movieNameAux not in relatedList:\n",
    "                    relatedList.append(movieNameAux)\n",
    "        \n",
    "        return relatedList\n",
    "    return listMovieName\n",
    "\n",
    "def get_movie_data(movieName, key=\"546c6742\"):\n",
    "    baseurl= \"http://www.omdbapi.com/\"\n",
    "    params_d = {}\n",
    "    params_d[\"t\"]= movieName\n",
    "    params_d[\"apikey\"]= key\n",
    "    params_d[\"r\"]= \"json\"\n",
    "    resp = requests.get(baseurl, params=params_d)\n",
    "    print(resp.url)\n",
    "    respDic = resp.json()\n",
    "    return respDic\n",
    "\n",
    "def get_movie_rating(movieNameJson):\n",
    "    strRanting=\"\"\n",
    "    for typeRantingList in movieNameJson[\"Ratings\"]:\n",
    "        if typeRantingList[\"Source\"]== \"Rotten Tomatoes\":\n",
    "            strRanting = typeRantingList[\"Value\"]\n",
    "    if strRanting != \"\":\n",
    "        ranting = int(strRanting[:2])\n",
    "    else: ranting = 0\n",
    "    return ranting\n",
    "\n",
    "def get_sorted_recommendations(listMovieTitle):\n",
    "    listMovie= get_related_titles(listMovieTitle)\n",
    "    listMovie= sorted(listMovie, key = lambda movieName: (get_movie_rating(get_movie_data(movieName)), movieName), reverse=True)\n",
    "    \n",
    "    return listMovie\n",
    "\n",
    "print(get_sorted_recommendations([\"Bridesmaids\", \"Sherlock Holmes\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
